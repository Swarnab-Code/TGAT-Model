{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Block 1: Mount Drive & Load Dataset"
      ],
      "metadata": {
        "id": "zZFoZCOnqlvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfZc79j_piWv",
        "outputId": "7d78130e-d5ab-4b0a-929c-ee6220e01ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   Unnamed: 0.1                                        from  \\\n",
            "0      10159229  0x219c5355f7496c47e743f5a6d98527509ea42444   \n",
            "1      10010990  0x21a1662d90d163f79f9e71fda42c60926e80699c   \n",
            "2      10159517  0xcbe64fb9fdee1eb4172d2bc375c12ace497ac253   \n",
            "3      13323550  0x007077061537f25eaf485a1e6fa4af64e883be98   \n",
            "4      13323549  0x7a44dbe0d1823cd177a9b4c35899046190811fb3   \n",
            "\n",
            "                                           to  amount     timestamp  \\\n",
            "0  0xaaaf91d9b90df800df4f55c205fd6989c977e73a     0.0  1.494145e+09   \n",
            "1  0xaaaf91d9b90df800df4f55c205fd6989c977e73a     0.0  1.494196e+09   \n",
            "2  0xaaaf91d9b90df800df4f55c205fd6989c977e73a     0.0  1.494145e+09   \n",
            "3  0xf0f8b0b8dbb1124261fc8d778e2287e3fd2cf4f5     0.0  1.494185e+09   \n",
            "4  0xf0f8b0b8dbb1124261fc8d778e2287e3fd2cf4f5     0.0  1.494184e+09   \n",
            "\n",
            "   fromIsPhi  toIsPhi                 date  Unnamed: 0  \n",
            "0          0        0  2017-05-07 00:00:00         NaN  \n",
            "1          0        0  2017-05-07 00:00:00         NaN  \n",
            "2          0        0  2017-05-07 00:00:00         NaN  \n",
            "3          0        0  2017-05-07 00:00:00         NaN  \n",
            "4          0        0  2017-05-07 00:00:00         NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 69486 entries, 0 to 69485\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Unnamed: 0.1  69486 non-null  int64  \n",
            " 1   from          69486 non-null  object \n",
            " 2   to            69486 non-null  object \n",
            " 3   amount        69486 non-null  float64\n",
            " 4   timestamp     69486 non-null  float64\n",
            " 5   fromIsPhi     69486 non-null  int64  \n",
            " 6   toIsPhi       69486 non-null  int64  \n",
            " 7   date          69486 non-null  object \n",
            " 8   Unnamed: 0    38221 non-null  float64\n",
            "dtypes: float64(3), int64(3), object(3)\n",
            "memory usage: 4.8+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset using pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Update the path if needed\n",
        "csv_path = '/content/drive/MyDrive/TGAT Model/clean_combined_dataset.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Show first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Show useful info about columns & data types\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2: Clean Data & Split by Month"
      ],
      "metadata": {
        "id": "RCY1JK33qowM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unwanted index columns\n",
        "df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'], inplace=True, errors='ignore')\n",
        "\n",
        "# Convert 'date' to datetime\n",
        "df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')\n",
        "\n",
        "# Drop rows with invalid dates\n",
        "df.dropna(subset=['date'], inplace=True)\n",
        "\n",
        "# Sort by timestamp for time consistency\n",
        "df.sort_values(by='timestamp', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)  # Optional but clean\n",
        "\n",
        "# Create 'month' column for splitting\n",
        "df['month'] = df['date'].dt.to_period(\"M\")\n",
        "\n",
        "# Split DataFrame into dictionary of monthly splits\n",
        "graph_splits = dict(tuple(df.groupby('month')))\n",
        "\n",
        "# Debug prints\n",
        "print(\"Number of months found:\", len(graph_splits))\n",
        "print(\"First few months:\", list(graph_splits.keys())[:5])\n",
        "print(\"Example month data (first month):\")\n",
        "print(graph_splits[list(graph_splits.keys())[0]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qhM_Oeiqq-Y",
        "outputId": "80b25f2e-1944-4b4e-af58-df2eb13660cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of months found: 23\n",
            "First few months: [Period('2016-11', 'M'), Period('2017-03', 'M'), Period('2017-05', 'M'), Period('2017-06', 'M'), Period('2017-07', 'M')]\n",
            "Example month data (first month):\n",
            "                                         from  \\\n",
            "0  0x70faa28a6b8d6829a4b1e649d26ec9a2a39ba413   \n",
            "1  0x9af3bf0b0a117d3fbfb37dfc7fa67f9a645488fc   \n",
            "\n",
            "                                           to      amount     timestamp  \\\n",
            "0  0x9af3bf0b0a117d3fbfb37dfc7fa67f9a645488fc  173.511739  1.480521e+09   \n",
            "1  0x03e9a232700c14fbc15b1187a734a7de2824ea97  347.346320  1.480533e+09   \n",
            "\n",
            "   fromIsPhi  toIsPhi       date    month  \n",
            "0          0        1 2016-11-30  2016-11  \n",
            "1          1        0 2016-11-30  2016-11  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 3.1: Build Temporal Graph with Time & Edge Features"
      ],
      "metadata": {
        "id": "eWeXU18itmqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def build_temporal_graph(month_df):\n",
        "    G = nx.DiGraph()\n",
        "    for _, row in month_df.iterrows():\n",
        "        src, dst = row['from'], row['to']\n",
        "        G.add_edge(src, dst,\n",
        "                   timestamp=row['timestamp'],\n",
        "                   amount=row['amount'])\n",
        "\n",
        "        # Node label (is_phishing)\n",
        "        G.nodes[src]['is_phishing'] = max(G.nodes[src].get('is_phishing', 0), row['fromIsPhi'])\n",
        "        G.nodes[dst]['is_phishing'] = max(G.nodes[dst].get('is_phishing', 0), row['toIsPhi'])\n",
        "    return G\n"
      ],
      "metadata": {
        "id": "tkhrU6tPtnwU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 4: Add Node Features"
      ],
      "metadata": {
        "id": "WeSbxsm2tu29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_basic_node_features(G):\n",
        "    for node in G.nodes():\n",
        "        in_deg = G.in_degree(node)\n",
        "        out_deg = G.out_degree(node)\n",
        "        total_sent = sum(G[u][v].get('amount', 0) for u, v in G.out_edges(node))\n",
        "        total_recv = sum(G[u][v].get('amount', 0) for u, v in G.in_edges(node))\n",
        "        G.nodes[node]['x'] = [in_deg, out_deg, total_sent, total_recv]\n"
      ],
      "metadata": {
        "id": "LGWxeJSXtwAB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 5: Convert to PyG + Add Timestamp & Labels"
      ],
      "metadata": {
        "id": "G7_ZDmNutzO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t4igZPq8ar2",
        "outputId": "6d0d2934-6310-4266-f16f-8930a0f257fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import from_networkx\n",
        "import torch\n",
        "\n",
        "def graph_to_pyg(G):\n",
        "    pyg_data = from_networkx(G, group_node_attrs=['x'], group_edge_attrs=['amount', 'timestamp'])\n",
        "    pyg_data.y = torch.tensor([G.nodes[n].get('is_phishing', 0) for n in G.nodes()], dtype=torch.long)\n",
        "    return pyg_data\n"
      ],
      "metadata": {
        "id": "QUVnOC-ht2x6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 6: Time Encoding (TGAT style)"
      ],
      "metadata": {
        "id": "pBRLwT3zuz04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def time_encoding(t_diff, d=16):\n",
        "    # Relative time encoding (cosine-based)\n",
        "    omega = torch.linspace(1, 1000, d)\n",
        "    bias = torch.rand(d)\n",
        "    return torch.cos(omega * t_diff.unsqueeze(-1) + bias)\n"
      ],
      "metadata": {
        "id": "GU6a4fmHu0zU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 7: TGAT Layer"
      ],
      "metadata": {
        "id": "LiAL7ipmu39Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class SimpleTGAT(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, time_dim=16):\n",
        "        super().__init__()\n",
        "        self.time_dim = time_dim\n",
        "        self.time_encoder = lambda t: time_encoding(t, d=self.time_dim)\n",
        "        self.gat1 = GATConv(in_dim + time_dim, hidden_dim, heads=2)\n",
        "        self.gat2 = GATConv(hidden_dim * 2, hidden_dim, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        timestamps = edge_attr[:, 1]  # shape: [num_edges]\n",
        "\n",
        "        # Encode time differences (relative to mean time)\n",
        "        t_ref = timestamps.mean()\n",
        "        t_diff = timestamps - t_ref\n",
        "        time_feat = self.time_encoder(t_diff)  # shape: [num_edges, time_dim]\n",
        "        time_feat = time_feat.to(x.device)\n",
        "\n",
        "        # === Match time features to nodes ===\n",
        "        # For each edge: assign time_feat to the source node of that edge\n",
        "        # This builds [num_nodes, time_dim] by aggregating edge-wise time features\n",
        "\n",
        "        # Step 1: initialize all time encodings as zeros\n",
        "        x_time = torch.zeros(x.size(0), self.time_dim).to(x.device)\n",
        "\n",
        "        # Step 2: accumulate time_feat for each source node\n",
        "        source_nodes = edge_index[0]\n",
        "        counts = torch.zeros(x.size(0)).to(x.device)\n",
        "\n",
        "        for i in range(edge_index.size(1)):\n",
        "            node = source_nodes[i]\n",
        "            x_time[node] += time_feat[i]\n",
        "            counts[node] += 1\n",
        "\n",
        "        # Step 3: avoid divide-by-zero, average\n",
        "        counts = counts.masked_fill(counts == 0, 1)\n",
        "        x_time = x_time / counts.unsqueeze(1)\n",
        "\n",
        "        # Step 4: concat node features with temporal features\n",
        "        x_combined = torch.cat([x, x_time], dim=1)\n",
        "\n",
        "        # Apply GAT layers\n",
        "        h = F.relu(self.gat1(x_combined, edge_index))\n",
        "        h = self.gat2(h, edge_index)\n",
        "        return h\n"
      ],
      "metadata": {
        "id": "LIxhpDxXu6VS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 8: Classifier"
      ],
      "metadata": {
        "id": "0owEZGZGvBRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PhishingClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "Ay3ShZR-vDue"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 9: Training Loop"
      ],
      "metadata": {
        "id": "hGSHa98AvGI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model instantiation\n",
        "embedder = SimpleTGAT(in_dim=4, hidden_dim=16)\n",
        "classifier = PhishingClassifier(16)\n",
        "\n",
        "params = list(embedder.parameters()) + list(classifier.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Build graph from first month\n",
        "month_list = list(graph_splits.keys())\n",
        "G = build_temporal_graph(graph_splits[month_list[0]])\n",
        "add_basic_node_features(G)\n",
        "data = graph_to_pyg(G)\n",
        "\n",
        "for epoch in range(100):\n",
        "    embedder.train()\n",
        "    classifier.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    h = embedder(data)\n",
        "    out = classifier(h)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        pred = out.argmax(dim=1)\n",
        "        acc = (pred == data.y).float().mean()\n",
        "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Acc: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teoWxGisvG81",
        "outputId": "bf177e16-67e5-4170-f9cb-7ca9a80ed083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 5.6325 | Acc: 0.3333\n",
            "Epoch 10 | Loss: 0.6058 | Acc: 0.6667\n",
            "Epoch 20 | Loss: 1.0568 | Acc: 0.6667\n",
            "Epoch 30 | Loss: 0.4441 | Acc: 0.6667\n",
            "Epoch 40 | Loss: 0.4763 | Acc: 0.6667\n",
            "Epoch 50 | Loss: 0.4648 | Acc: 0.6667\n",
            "Epoch 60 | Loss: 0.4632 | Acc: 0.6667\n",
            "Epoch 70 | Loss: 0.4282 | Acc: 1.0000\n",
            "Epoch 80 | Loss: 0.4832 | Acc: 0.6667\n",
            "Epoch 90 | Loss: 0.4600 | Acc: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 10: Evaluation"
      ],
      "metadata": {
        "id": "UHmwsQpWvJkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "embedder.eval()\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    h = embedder(data)\n",
        "    pred = classifier(h).argmax(dim=1)\n",
        "print(classification_report(data.y.cpu(), pred.cpu(), target_names=[\"Normal\", \"Phishing\"]))\n",
        "\n",
        "# Assign X and y for later use (e.g., t-SNE, metrics, etc.)\n",
        "X = h\n",
        "y = data.y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpZDHWLEvOrh",
        "outputId": "c8ae7a9c-52d8-4337-aec1-091281ac1b1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       1.00      0.50      0.67         2\n",
            "    Phishing       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TGAT Model Pipeline (PDTGA)"
      ],
      "metadata": {
        "id": "2HboEmJE7kEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph with Temporal Edges ➝ Time-Aware TGAT Encoder ➝ Node Embeddings ➝ MLP Classifier ➝ Evaluation Report"
      ],
      "metadata": {
        "id": "Z6U_hoc47mxo"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}